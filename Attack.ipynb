{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import inception\n",
    "import math\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import glob\n",
    "\n",
    "inception.data_dir = 'inception/'\n",
    "\n",
    "inception.maybe_download()\n",
    "model = inception.Inception()\n",
    "resized_image = model.resized_image\n",
    "y_pred = model.y_pred\n",
    "y_logits = model.y_logits\n",
    "\n",
    "# Set the graph for the Inception model as the default graph,\n",
    "# so that all changes inside this with-block are done to that graph.\n",
    "with model.graph.as_default():\n",
    "    # Add a placeholder variable for the target class-number.\n",
    "    # This will be set to e.g. 300 for the 'bookcase' class.\n",
    "    pl_cls_target = tf.placeholder(dtype=tf.int32)\n",
    "\n",
    "    # Add a new loss-function. This is the cross-entropy.\n",
    "    # See Tutorial #01 for an explanation of cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_logits, labels=[pl_cls_target])\n",
    "\n",
    "    # Get the gradient for the loss-function with regard to\n",
    "    # the resized input image.\n",
    "    gradient = tf.gradients(loss, resized_image)\n",
    "\n",
    "session = tf.Session(graph=model.graph)\n",
    "time = datetime.datetime.now().strftime('%m%d%H%M%S')\n",
    "\n",
    "images = glob.glob(\"./images/*.JPEG\")\n",
    "\n",
    "# Parameter configs\n",
    "cls_target=300\n",
    "noise_limit=3.0\n",
    "required_score=0.99\n",
    "show_image=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(x):\n",
    "    # Get the min and max values for all pixels in the input.\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "\n",
    "    # Normalize so all values are between 0.0 and 1.0\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the image is still classified as original class\n",
    "def test_precision(i, image):\n",
    "    test_image = np.clip(a=image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "    # Create a feed-dict. This feeds the noisy image to the\n",
    "    # tensor in the graph that holds the resized image, because\n",
    "    # this is the final stage for inputting raw image data.\n",
    "    # This also feeds the target class-number that we desire.\n",
    "    feed_dict = {model.tensor_name_resized_image: [test_image],\n",
    "                 pl_cls_target: cls_target}\n",
    "\n",
    "    # Calculate the predicted class-scores as well as the gradient.\n",
    "    pred, grad = session.run([y_pred, gradient],\n",
    "                             feed_dict=feed_dict)\n",
    "\n",
    "    final_class = np.argmax(pred)\n",
    "    '''\n",
    "    \n",
    "    # Names for the source and target classes.\n",
    "    name_source = model.name_lookup.cls_to_name(final_class,\n",
    "                                                only_first_name=True)\n",
    "    print('is classified as {} with score {}'. format(name_source, pred.max()))\n",
    "    '''\n",
    "    \n",
    "    # Convert the predicted class-scores to a one-dim array.\n",
    "    pred = np.squeeze(pred)\n",
    "\n",
    "    # The scores (probabilities) for the source and target classes.\n",
    "    score_source = pred[cls_source]\n",
    "    score_target = pred[cls_target]\n",
    "\n",
    "    return score_source > score_target, final_class == cls_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense: TV compression\n",
    "# Simple heuristic to implement total variance\n",
    "def tv_compress(image):\n",
    "    lambda_tv = 0.5\n",
    "    bernoulli_p = 0.25\n",
    "    A = image\n",
    "    # TODO: make it stop at diff < threshold instead of 100 iterations\n",
    "    for x in range(100):\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(A.shape[1]):\n",
    "                if np.random.random() > 0.25:\n",
    "                    continue\n",
    "                cnt_ = 0\n",
    "                sum_ = 0\n",
    "                # Self cell\n",
    "                cnt_ += 1\n",
    "                sum_ += A[i, j]\n",
    "                # Adjecent cells\n",
    "                if(i > 0):\n",
    "                    cnt_ += lambda_tv\n",
    "                    sum_ += A[i-1, j] * lambda_tv\n",
    "                if(j > 0):\n",
    "                    cnt_ += lambda_tv\n",
    "                    sum_ += A[i, j-1] * lambda_tv\n",
    "                if(i < A.shape[0]-1):\n",
    "                    cnt_ += lambda_tv\n",
    "                    sum_ += A[i+1, j] * lambda_tv\n",
    "                if(j < A.shape[1]-1):\n",
    "                    cnt_ += lambda_tv\n",
    "                    sum_ += A[i, j+1] * lambda_tv\n",
    "                A[i, j] = sum_ / cnt_\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense: bit compression\n",
    "def bit_compress(image, compress_bit):\n",
    "    compressed_image = image\n",
    "    for i in range(compressed_image.shape[0]):\n",
    "        for j in range(compressed_image.shape[1]):\n",
    "            for k in range(compressed_image.shape[2]):\n",
    "                compressed_image[i,j,k] -= compressed_image[i,j,k]% math.pow(2, compress_bit)\n",
    "    return compressed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense: kmeans\n",
    "def find_nearest_cluster(current_pixel, k_means):\n",
    "\tdiff_sq = np.square(k_means - np.tile(current_pixel,(16,1)))\n",
    "\tsum_of_sq = diff_sq[:,0] + diff_sq[:,1] + diff_sq[:,2]\n",
    "\treturn np.argmin(sum_of_sq)\n",
    "\n",
    "def kmeans_compress(image):\n",
    "# (b) Calculate 16 means' centroid\n",
    "    A = image\n",
    "    k = 16\n",
    "# Random initialize each k-mean's centroid from a cell in small picture\n",
    "    index1 = np.random.randint(0,A.shape[0],k)\n",
    "    index2 = np.random.randint(0,A.shape[1],k)\n",
    "    k_means = A[index1, index2, :].astype(float)\n",
    "    for x in range(100):\n",
    "        new_means = np.zeros((k, A.shape[2])).astype(float)\n",
    "        new_means_count = np.zeros(k).astype(float)\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(A.shape[1]):\n",
    "                nearest_centroid = find_nearest_cluster(A[i,j,:], k_means)\n",
    "                new_means_count[nearest_centroid] += 1\n",
    "                new_means[nearest_centroid] += A[i,j,:]\n",
    "\t# Replace the k-means with new centroids\n",
    "        k_means = np.divide(new_means,np.tile(new_means_count, (3,1)).T)\n",
    "\n",
    "# (c) Replace large image's all color with the nearest centroid's color\n",
    "    compressed_image = image\n",
    "    for i in range(compressed_image.shape[0]):\n",
    "        for j in range(compressed_image.shape[1]):\n",
    "            nearest_centroid = find_nearest_cluster(compressed_image[i,j,:], k_means)\n",
    "            compressed_image[i,j,:] = k_means[nearest_centroid]\n",
    "        \n",
    "    return compressed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense: spatial smoothing, right now using 3X3\n",
    "def median(lst):\n",
    "    quotient, remainder = divmod(len(lst), 2)\n",
    "    if remainder:\n",
    "        return sorted(lst)[quotient]\n",
    "    return sum(sorted(lst)[quotient - 1:quotient + 1]) / 2.\n",
    "\n",
    "def checkindex(image, index_x, index_y):\n",
    "    if(index_x < 0 or index_x >= image.shape[0]):\n",
    "        return False;\n",
    "    if(index_y < 0 or index_y >= image.shape[1]):\n",
    "        return False;\n",
    "    return True;\n",
    "\n",
    "def find_median_in_sliding_windown(image, i, j, k, m, n):\n",
    "    list = []\n",
    "    for x in range(-m+1, m):\n",
    "        for y in range(-n+1, n):\n",
    "            if(checkindex(image, i+x, j+y)):\n",
    "                list.append(image[i+x, j+y, k])\n",
    "    return median(list)\n",
    "            \n",
    "# m = n = 1 is just using the pixel itself, i.e. no change\n",
    "def spatial_smoothing(image, m, n):\n",
    "    compressed_image = image\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            for k in range(image.shape[2]):\n",
    "                compressed_image[i, j, k] = find_median_in_sliding_windown(image, i, j, k, m, n)\n",
    "    return compressed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_compression_run():\n",
    "        #Experiment on bit compression\n",
    "        total = len(images)\n",
    "        success1 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        success2 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        success3 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        # If it remained in same class\n",
    "        precision1 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        precision2 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        precision3 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "\n",
    "        threshold = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "        for image in images:\n",
    "            feed_dict = model._create_feed_dict(image_path=image)\n",
    "\n",
    "            #image = img[100]\n",
    "            #image_path= 'cifar/'\n",
    "            #feed_dict = model._create_feed_dict(image=image)\n",
    "\n",
    "\n",
    "\n",
    "            pred, image = session.run([y_pred, resized_image],\n",
    "                                          feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cls_source = np.argmax(pred)\n",
    "            cls_target = 300\n",
    "\n",
    "            # Score for the predicted class (aka. probability or confidence).\n",
    "            score_source_org = pred.max()\n",
    "\n",
    "            # Names for the source and target classes.\n",
    "            name_source = model.name_lookup.cls_to_name(cls_source,\n",
    "                                                        only_first_name=True)\n",
    "            name_target = model.name_lookup.cls_to_name(cls_target,\n",
    "                                                        only_first_name=True)\n",
    "\n",
    "            # Initialize the noise to zero.\n",
    "            noise = 0\n",
    "            iterations = 0\n",
    "            # Perform a number of optimization iterations to find\n",
    "            # the noise that causes mis-classification of the input image.\n",
    "            index = 0\n",
    "            for i in range(10000):\n",
    "                iterations = i\n",
    "\n",
    "                # The noisy image is just the sum of the input image and noise.\n",
    "                noisy_image = image + noise\n",
    "\n",
    "                # Ensure the pixel-values of the noisy image are between\n",
    "                # 0 and 255 like a real image. If we allowed pixel-values\n",
    "                # outside this range then maybe the mis-classification would\n",
    "                # be due to this 'illegal' input breaking the Inception model.\n",
    "                noisy_image = np.clip(a=noisy_image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "                # Create a feed-dict. This feeds the noisy image to the\n",
    "                # tensor in the graph that holds the resized image, because\n",
    "                # this is the final stage for inputting raw image data.\n",
    "                # This also feeds the target class-number that we desire.\n",
    "                feed_dict = {model.tensor_name_resized_image: noisy_image,\n",
    "                             pl_cls_target: cls_target}\n",
    "\n",
    "                # Calculate the predicted class-scores as well as the gradient.\n",
    "                pred, grad = session.run([y_pred, gradient],\n",
    "                                         feed_dict=feed_dict)\n",
    "\n",
    "                # Convert the predicted class-scores to a one-dim array.\n",
    "                pred = np.squeeze(pred)\n",
    "\n",
    "                # The scores (probabilities) for the source and target classes.\n",
    "                score_source = pred[cls_source]\n",
    "                score_target = pred[cls_target]\n",
    "\n",
    "                # Squeeze the dimensionality for the gradient-array.\n",
    "                grad = np.array(grad).squeeze()\n",
    "\n",
    "                # The gradient now tells us how much we need to change the\n",
    "                # noisy input image in order to move the predicted class\n",
    "                # closer to the desired target-class.\n",
    "\n",
    "                # Calculate the max of the absolute gradient values.\n",
    "                # This is used to calculate the step-size.\n",
    "                grad_absmax = np.abs(grad).max()\n",
    "\n",
    "                # If the gradient is very small then use a lower limit,\n",
    "                # because we will use it as a divisor.\n",
    "                if grad_absmax < 1e-10:\n",
    "                    grad_absmax = 1e-10\n",
    "\n",
    "                # Calculate the step-size for updating the image-noise.\n",
    "                # This ensures that at least one pixel colour is changed by 7.\n",
    "                # Recall that pixel colours can have 255 different values.\n",
    "                # This step-size was found to give fast convergence.\n",
    "                step_size = 1. / grad_absmax\n",
    "\n",
    "\n",
    "                '''\n",
    "                l2_disturb = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "\n",
    "                step_size = 0.1 / max(0.00001, math.sqrt(l2_disturb))\n",
    "                '''\n",
    "\n",
    "                test_precision(iterations, (image + noise)[0])\n",
    "\n",
    "                #l2_norm = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "                l2_norm = math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))\n",
    "                print ('l2 norm is {}'.format(math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))))\n",
    "\n",
    "                # If the score for the target-class is not high enough.\n",
    "                if index < len(threshold):\n",
    "                #if score_target < required_score and index < len(threshold):\n",
    "                    # Update the image-noise by subtracting the gradient\n",
    "                    # scaled by the step-size.\n",
    "                    noise -= step_size * grad\n",
    "\n",
    "                    # Ensure the noise is within the desired range.\n",
    "                    # This avoids distorting the image too much.\n",
    "                    noise = np.clip(a=noise,\n",
    "                                    a_min=-noise_limit,\n",
    "                                    a_max=noise_limit)\n",
    "                    '''\n",
    "                    if (iterations % 10 == 0):\n",
    "                        print(\"Print defense effect\")\n",
    "                        # Chose whatever defense method you want to use on the bottom.\n",
    "                        test_precision(iterations, spatial_smoothing((image + noise)[0], 3, 3))\n",
    "                    '''\n",
    "\n",
    "                    if l2_norm >= threshold[index]:\n",
    "                        #print(\"inside while loop\")\n",
    "                        # Abort the optimization because the score is high enough.\n",
    "                        x_1, x_2 = test_precision(iterations, bit_compress((image + noise)[0], 2))\n",
    "                        y_1, y_2 = test_precision(iterations, bit_compress((image + noise)[0], 4))\n",
    "                        z_1, z_2 = test_precision(iterations, bit_compress((image + noise)[0], 6))\n",
    "                        success1[index] += x_1\n",
    "                        success2[index] += y_1\n",
    "                        success3[index] += z_1    \n",
    "                        precision1[index] += x_2\n",
    "                        precision2[index] += y_2\n",
    "                        precision3[index] += z_2    \n",
    "\n",
    "                        if(x_1!=0 or y_1!=0 or z_1!=0):\n",
    "                            #print(\"index is \", index)\n",
    "                            index += 1\n",
    "                        else:\n",
    "                            index += 10\n",
    "\n",
    "                else:  \n",
    "                    print(success1)\n",
    "                    print(success2)\n",
    "                    print(success3)\n",
    "                    print(precision1)\n",
    "                    print(precision2)\n",
    "                    print(precision3)\n",
    "\n",
    "                    break;\n",
    "\n",
    "            print(\"finished image \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmean_with_16_centroids_run():\n",
    "        # Kmean with 16 centroids\n",
    "        total = len(images)\n",
    "        success = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        precision = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        threshold = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "        for image in images:\n",
    "            feed_dict = model._create_feed_dict(image_path=image)\n",
    "\n",
    "            #image = img[100]\n",
    "            #image_path= 'cifar/'\n",
    "            #feed_dict = model._create_feed_dict(image=image)\n",
    "\n",
    "\n",
    "\n",
    "            pred, image = session.run([y_pred, resized_image],\n",
    "                                          feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cls_source = np.argmax(pred)\n",
    "            cls_target = 300\n",
    "\n",
    "            # Score for the predicted class (aka. probability or confidence).\n",
    "            score_source_org = pred.max()\n",
    "\n",
    "            # Names for the source and target classes.\n",
    "            name_source = model.name_lookup.cls_to_name(cls_source,\n",
    "                                                        only_first_name=True)\n",
    "            name_target = model.name_lookup.cls_to_name(cls_target,\n",
    "                                                        only_first_name=True)\n",
    "\n",
    "            # Initialize the noise to zero.\n",
    "            noise = 0\n",
    "            iterations = 0\n",
    "            # Perform a number of optimization iterations to find\n",
    "            # the noise that causes mis-classification of the input image.\n",
    "            index = 0\n",
    "            for i in range(10000):\n",
    "                iterations = i\n",
    "\n",
    "                # The noisy image is just the sum of the input image and noise.\n",
    "                noisy_image = image + noise\n",
    "\n",
    "                # Ensure the pixel-values of the noisy image are between\n",
    "                # 0 and 255 like a real image. If we allowed pixel-values\n",
    "                # outside this range then maybe the mis-classification would\n",
    "                # be due to this 'illegal' input breaking the Inception model.\n",
    "                noisy_image = np.clip(a=noisy_image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "                # Create a feed-dict. This feeds the noisy image to the\n",
    "                # tensor in the graph that holds the resized image, because\n",
    "                # this is the final stage for inputting raw image data.\n",
    "                # This also feeds the target class-number that we desire.\n",
    "                feed_dict = {model.tensor_name_resized_image: noisy_image,\n",
    "                             pl_cls_target: cls_target}\n",
    "\n",
    "                # Calculate the predicted class-scores as well as the gradient.\n",
    "                pred, grad = session.run([y_pred, gradient],\n",
    "                                         feed_dict=feed_dict)\n",
    "\n",
    "                # Convert the predicted class-scores to a one-dim array.\n",
    "                pred = np.squeeze(pred)\n",
    "\n",
    "                # The scores (probabilities) for the source and target classes.\n",
    "                score_source = pred[cls_source]\n",
    "                score_target = pred[cls_target]\n",
    "\n",
    "                # Squeeze the dimensionality for the gradient-array.\n",
    "                grad = np.array(grad).squeeze()\n",
    "\n",
    "                # The gradient now tells us how much we need to change the\n",
    "                # noisy input image in order to move the predicted class\n",
    "                # closer to the desired target-class.\n",
    "\n",
    "                # Calculate the max of the absolute gradient values.\n",
    "                # This is used to calculate the step-size.\n",
    "                grad_absmax = np.abs(grad).max()\n",
    "\n",
    "                # If the gradient is very small then use a lower limit,\n",
    "                # because we will use it as a divisor.\n",
    "                if grad_absmax < 1e-10:\n",
    "                    grad_absmax = 1e-10\n",
    "\n",
    "                # Calculate the step-size for updating the image-noise.\n",
    "                # This ensures that at least one pixel colour is changed by 7.\n",
    "                # Recall that pixel colours can have 255 different values.\n",
    "                # This step-size was found to give fast convergence.\n",
    "                step_size = 1. / grad_absmax\n",
    "\n",
    "\n",
    "                '''\n",
    "                l2_disturb = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "\n",
    "                step_size = 0.1 / max(0.00001, math.sqrt(l2_disturb))\n",
    "                '''\n",
    "\n",
    "                test_precision(iterations, (image + noise)[0])\n",
    "\n",
    "                #l2_norm = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "                l2_norm = math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))\n",
    "                print ('l2 norm is {}'.format(math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))))\n",
    "\n",
    "                # If the score for the target-class is not high enough.\n",
    "                if index < len(threshold):\n",
    "                #if score_target < required_score and index < len(threshold):\n",
    "                    # Update the image-noise by subtracting the gradient\n",
    "                    # scaled by the step-size.\n",
    "                    noise -= step_size * grad\n",
    "\n",
    "                    # Ensure the noise is within the desired range.\n",
    "                    # This avoids distorting the image too much.\n",
    "                    noise = np.clip(a=noise,\n",
    "                                    a_min=-noise_limit,\n",
    "                                    a_max=noise_limit)\n",
    "                    '''\n",
    "                    if (iterations % 10 == 0):\n",
    "                        print(\"Print defense effect\")\n",
    "                        # Chose whatever defense method you want to use on the bottom.\n",
    "                        test_precision(iterations, spatial_smoothing((image + noise)[0], 3, 3))\n",
    "                    '''\n",
    "\n",
    "                    if l2_norm >= threshold[index]:\n",
    "                        #print(\"inside while loop\")\n",
    "                        # Abort the optimization because the score is high enough.\n",
    "                        x1, x2 = test_precision(iterations, kmeans_compress((image + noise)[0]))\n",
    "                        success[index] += x1\n",
    "                        precision[index] += x2    \n",
    "                        if(x1==1):\n",
    "                            #print(\"index is \", index)\n",
    "                            index += 1\n",
    "                        else:\n",
    "                            index += 10\n",
    "\n",
    "                else:  \n",
    "                    print(success)\n",
    "                    break;\n",
    "\n",
    "            print(\"finished image \")\n",
    "\n",
    "\n",
    "        #print(\"limit\", l2_limit, \"successful rate is \", success/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_smoothing_run():\n",
    "        # Spatial smoothing\n",
    "        total = len(images)\n",
    "        success = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        precision = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        threshold = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "        for image in images:\n",
    "            feed_dict = model._create_feed_dict(image_path=image)\n",
    "\n",
    "            #image = img[100]\n",
    "            #image_path= 'cifar/'\n",
    "            #feed_dict = model._create_feed_dict(image=image)\n",
    "\n",
    "\n",
    "\n",
    "            pred, image = session.run([y_pred, resized_image],\n",
    "                                          feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cls_source = np.argmax(pred)\n",
    "            cls_target = 300\n",
    "\n",
    "            # Score for the predicted class (aka. probability or confidence).\n",
    "            score_source_org = pred.max()\n",
    "\n",
    "            # Names for the source and target classes.\n",
    "            name_source = model.name_lookup.cls_to_name(cls_source,\n",
    "                                                        only_first_name=True)\n",
    "            name_target = model.name_lookup.cls_to_name(cls_target,\n",
    "                                                        only_first_name=True)\n",
    "\n",
    "            # Initialize the noise to zero.\n",
    "            noise = 0\n",
    "            iterations = 0\n",
    "            # Perform a number of optimization iterations to find\n",
    "            # the noise that causes mis-classification of the input image.\n",
    "            index = 0\n",
    "            for i in range(10000):\n",
    "                iterations = i\n",
    "\n",
    "                # The noisy image is just the sum of the input image and noise.\n",
    "                noisy_image = image + noise\n",
    "\n",
    "                # Ensure the pixel-values of the noisy image are between\n",
    "                # 0 and 255 like a real image. If we allowed pixel-values\n",
    "                # outside this range then maybe the mis-classification would\n",
    "                # be due to this 'illegal' input breaking the Inception model.\n",
    "                noisy_image = np.clip(a=noisy_image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "                # Create a feed-dict. This feeds the noisy image to the\n",
    "                # tensor in the graph that holds the resized image, because\n",
    "                # this is the final stage for inputting raw image data.\n",
    "                # This also feeds the target class-number that we desire.\n",
    "                feed_dict = {model.tensor_name_resized_image: noisy_image,\n",
    "                             pl_cls_target: cls_target}\n",
    "\n",
    "                # Calculate the predicted class-scores as well as the gradient.\n",
    "                pred, grad = session.run([y_pred, gradient],\n",
    "                                         feed_dict=feed_dict)\n",
    "\n",
    "                # Convert the predicted class-scores to a one-dim array.\n",
    "                pred = np.squeeze(pred)\n",
    "\n",
    "                # The scores (probabilities) for the source and target classes.\n",
    "                score_source = pred[cls_source]\n",
    "                score_target = pred[cls_target]\n",
    "\n",
    "                # Squeeze the dimensionality for the gradient-array.\n",
    "                grad = np.array(grad).squeeze()\n",
    "\n",
    "                # The gradient now tells us how much we need to change the\n",
    "                # noisy input image in order to move the predicted class\n",
    "                # closer to the desired target-class.\n",
    "\n",
    "                # Calculate the max of the absolute gradient values.\n",
    "                # This is used to calculate the step-size.\n",
    "                grad_absmax = np.abs(grad).max()\n",
    "\n",
    "                # If the gradient is very small then use a lower limit,\n",
    "                # because we will use it as a divisor.\n",
    "                if grad_absmax < 1e-10:\n",
    "                    grad_absmax = 1e-10\n",
    "\n",
    "                # Calculate the step-size for updating the image-noise.\n",
    "                # This ensures that at least one pixel colour is changed by 7.\n",
    "                # Recall that pixel colours can have 255 different values.\n",
    "                # This step-size was found to give fast convergence.\n",
    "                step_size = 1. / grad_absmax\n",
    "\n",
    "\n",
    "                '''\n",
    "                l2_disturb = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "\n",
    "                step_size = 0.1 / max(0.00001, math.sqrt(l2_disturb))\n",
    "                '''\n",
    "\n",
    "                test_precision(iterations, (image + noise)[0])\n",
    "\n",
    "                #l2_norm = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "                l2_norm = math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))\n",
    "                print ('l2 norm is {}'.format(math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))))\n",
    "\n",
    "                # If the score for the target-class is not high enough.\n",
    "                if index < len(threshold):\n",
    "                #if score_target < required_score and index < len(threshold):\n",
    "                    # Update the image-noise by subtracting the gradient\n",
    "                    # scaled by the step-size.\n",
    "                    noise -= step_size * grad\n",
    "\n",
    "                    # Ensure the noise is within the desired range.\n",
    "                    # This avoids distorting the image too much.\n",
    "                    noise = np.clip(a=noise,\n",
    "                                    a_min=-noise_limit,\n",
    "                                    a_max=noise_limit)\n",
    "                    '''\n",
    "                    if (iterations % 10 == 0):\n",
    "                        print(\"Print defense effect\")\n",
    "                        # Chose whatever defense method you want to use on the bottom.\n",
    "                        test_precision(iterations, spatial_smoothing((image + noise)[0], 3, 3))\n",
    "                    '''\n",
    "\n",
    "                    if l2_norm >= threshold[index]:\n",
    "                        #print(\"inside while loop\")\n",
    "                        # Abort the optimization because the score is high enough.\n",
    "                        x1, x2 = test_precision(iterations, kmeans_compress((image + noise)[0]))\n",
    "                        success[index] += x1\n",
    "                        precision[index] += x2    \n",
    "                        if(x1==1):\n",
    "                            #print(\"index is \", index)\n",
    "                            index += 1\n",
    "                        else:\n",
    "                            index += 10\n",
    "\n",
    "                else:  \n",
    "                    print(success)\n",
    "                    print(precision)\n",
    "                    break;\n",
    "\n",
    "            print(\"finished image \")\n",
    "\n",
    "\n",
    "        #print(\"limit\", l2_limit, \"successful rate is \", success/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_compression_with_iterative_FGSM_run():\n",
    "        #Experiment on bit compression, with iterative FGSM\n",
    "        total = len(images)\n",
    "        success1 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        success2 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        success3 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        # If it remained in same class\n",
    "        precision1 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        precision2 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        precision3 = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "\n",
    "        threshold = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "        for image in images:\n",
    "            feed_dict = model._create_feed_dict(image_path=image)\n",
    "\n",
    "            #image = img[100]\n",
    "            #image_path= 'cifar/'\n",
    "            #feed_dict = model._create_feed_dict(image=image)\n",
    "\n",
    "\n",
    "\n",
    "            pred, image = session.run([y_pred, resized_image],\n",
    "                                          feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cls_source = np.argmax(pred)\n",
    "            cls_target = 300\n",
    "\n",
    "            # Score for the predicted class (aka. probability or confidence).\n",
    "            score_source_org = pred.max()\n",
    "\n",
    "            # Names for the source and target classes.\n",
    "            name_source = model.name_lookup.cls_to_name(cls_source,\n",
    "                                                        only_first_name=True)\n",
    "            name_target = model.name_lookup.cls_to_name(cls_target,\n",
    "                                                        only_first_name=True)\n",
    "\n",
    "            # Initialize the noise to zero.\n",
    "            noise = 0\n",
    "            iterations = 0\n",
    "            # Perform a number of optimization iterations to find\n",
    "            # the noise that causes mis-classification of the input image.\n",
    "            index = 0\n",
    "            for i in range(10000):\n",
    "                iterations = i\n",
    "\n",
    "                # The noisy image is just the sum of the input image and noise.\n",
    "                noisy_image = image + noise\n",
    "\n",
    "                # Ensure the pixel-values of the noisy image are between\n",
    "                # 0 and 255 like a real image. If we allowed pixel-values\n",
    "                # outside this range then maybe the mis-classification would\n",
    "                # be due to this 'illegal' input breaking the Inception model.\n",
    "                noisy_image = np.clip(a=noisy_image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "                # Create a feed-dict. This feeds the noisy image to the\n",
    "                # tensor in the graph that holds the resized image, because\n",
    "                # this is the final stage for inputting raw image data.\n",
    "                # This also feeds the target class-number that we desire.\n",
    "                feed_dict = {model.tensor_name_resized_image: noisy_image,\n",
    "                             pl_cls_target: cls_target}\n",
    "\n",
    "                # Calculate the predicted class-scores as well as the gradient.\n",
    "                pred, grad = session.run([y_pred, gradient],\n",
    "                                         feed_dict=feed_dict)\n",
    "\n",
    "                # Convert the predicted class-scores to a one-dim array.\n",
    "                pred = np.squeeze(pred)\n",
    "\n",
    "                # The scores (probabilities) for the source and target classes.\n",
    "                score_source = pred[cls_source]\n",
    "                score_target = pred[cls_target]\n",
    "\n",
    "                # Squeeze the dimensionality for the gradient-array.\n",
    "                grad = np.array(grad).squeeze()\n",
    "\n",
    "                # The gradient now tells us how much we need to change the\n",
    "                # noisy input image in order to move the predicted class\n",
    "                # closer to the desired target-class.\n",
    "\n",
    "                # Calculate the max of the absolute gradient values.\n",
    "                # This is used to calculate the step-size.\n",
    "                grad_absmax = np.abs(grad).max()\n",
    "\n",
    "                # If the gradient is very small then use a lower limit,\n",
    "                # because we will use it as a divisor.\n",
    "                if grad_absmax < 1e-10:\n",
    "                    grad_absmax = 1e-10\n",
    "\n",
    "                # Calculate the step-size for updating the image-noise.\n",
    "                # This ensures that at least one pixel colour is changed by 7.\n",
    "                # Recall that pixel colours can have 255 different values.\n",
    "                # This step-size was found to give fast convergence.\n",
    "\n",
    "                # Iterative FGSM goes smaller steps, but more steps\n",
    "                step_size = 0.3 / grad_absmax\n",
    "\n",
    "\n",
    "                '''\n",
    "                l2_disturb = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "\n",
    "                step_size = 0.1 / max(0.00001, math.sqrt(l2_disturb))\n",
    "                '''\n",
    "\n",
    "                test_precision(iterations, (image + noise)[0])\n",
    "\n",
    "                #l2_norm = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "                l2_norm = math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))\n",
    "                print ('l2 norm is {}'.format(math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))))\n",
    "\n",
    "                # If the score for the target-class is not high enough.\n",
    "                if index < len(threshold):\n",
    "                #if score_target < required_score and index < len(threshold):\n",
    "                    # Update the image-noise by subtracting the gradient\n",
    "                    # scaled by the step-size.\n",
    "                    noise -= step_size * grad\n",
    "\n",
    "                    # Ensure the noise is within the desired range.\n",
    "                    # This avoids distorting the image too much.\n",
    "                    noise = np.clip(a=noise,\n",
    "                                    a_min=-noise_limit,\n",
    "                                    a_max=noise_limit)\n",
    "                    '''\n",
    "                    if (iterations % 10 == 0):\n",
    "                        print(\"Print defense effect\")\n",
    "                        # Chose whatever defense method you want to use on the bottom.\n",
    "                        test_precision(iterations, spatial_smoothing((image + noise)[0], 3, 3))\n",
    "                    '''\n",
    "\n",
    "                    if i%5!=0:\n",
    "                        continue;\n",
    "\n",
    "                    # Only test it every 5 iterations\n",
    "                    if l2_norm >= threshold[index]:\n",
    "                        #print(\"inside while loop\")\n",
    "                        # Abort the optimization because the score is high enough.\n",
    "                        x_1, x_2 = test_precision(iterations, bit_compress((image + noise)[0], 2))\n",
    "                        y_1, y_2 = test_precision(iterations, bit_compress((image + noise)[0], 4))\n",
    "                        z_1, z_2 = test_precision(iterations, bit_compress((image + noise)[0], 6))\n",
    "                        success1[index] += x_1\n",
    "                        success2[index] += y_1\n",
    "                        success3[index] += z_1    \n",
    "                        precision1[index] += x_2\n",
    "                        precision2[index] += y_2\n",
    "                        precision3[index] += z_2    \n",
    "\n",
    "                        if(x_1!=0 or y_1!=0 or z_1!=0):\n",
    "                            #print(\"index is \", index)\n",
    "                            index += 1\n",
    "                        else:\n",
    "                            index += 10\n",
    "\n",
    "                else:  \n",
    "                    print(success1)\n",
    "                    print(success2)\n",
    "                    print(success3)\n",
    "                    print(precision1)\n",
    "                    print(precision2)\n",
    "                    print(precision3)\n",
    "\n",
    "                    break;\n",
    "\n",
    "            print(\"finished image \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_compression_run()\n",
    "#kmean_with_16_centroids_run()\n",
    "#spatial_smoothing_run()\n",
    "#bit_compression_with_iterative_FGSM_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
