{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Inception v3 Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import inception\n",
    "import math\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import glob\n",
    "\n",
    "inception.data_dir = 'inception/'\n",
    "\n",
    "inception.maybe_download()\n",
    "model = inception.Inception()\n",
    "resized_image = model.resized_image\n",
    "y_pred = model.y_pred\n",
    "y_logits = model.y_logits\n",
    "\n",
    "# Set the graph for the Inception model as the default graph,\n",
    "# so that all changes inside this with-block are done to that graph.\n",
    "with model.graph.as_default():\n",
    "    # Add a placeholder variable for the target class-number.\n",
    "    # This will be set to e.g. 300 for the 'bookcase' class.\n",
    "    pl_cls_target = tf.placeholder(dtype=tf.int32)\n",
    "\n",
    "    # Add a new loss-function. This is the cross-entropy.\n",
    "    # See Tutorial #01 for an explanation of cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_logits, labels=[pl_cls_target])\n",
    "\n",
    "    # Get the gradient for the loss-function with regard to\n",
    "    # the resized input image.\n",
    "    gradient = tf.gradients(loss, resized_image)\n",
    "\n",
    "session = tf.Session(graph=model.graph)\n",
    "time = datetime.datetime.now().strftime('%m%d%H%M%S')\n",
    "\n",
    "images = glob.glob(\"./images/*.JPEG\")\n",
    "\n",
    "# Parameter configs\n",
    "cls_target=300\n",
    "noise_limit=3.0\n",
    "required_score=0.99\n",
    "show_image=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(x):\n",
    "    # Get the min and max values for all pixels in the input.\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "\n",
    "    # Normalize so all values are between 0.0 and 1.0\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_precision(i, image):\n",
    "    test_image = np.clip(a=image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "    # Create a feed-dict. This feeds the noisy image to the\n",
    "    # tensor in the graph that holds the resized image, because\n",
    "    # this is the final stage for inputting raw image data.\n",
    "    # This also feeds the target class-number that we desire.\n",
    "    feed_dict = {model.tensor_name_resized_image: [test_image],\n",
    "                 pl_cls_target: cls_target}\n",
    "\n",
    "    # Calculate the predicted class-scores as well as the gradient.\n",
    "    pred, grad = session.run([y_pred, gradient],\n",
    "                             feed_dict=feed_dict)\n",
    "\n",
    "    '''\n",
    "    final_class = np.argmax(pred)\n",
    "\n",
    "    # Names for the source and target classes.\n",
    "    name_source = model.name_lookup.cls_to_name(final_class,\n",
    "                                                only_first_name=True)\n",
    "    print('is classified as {} with score {}'. format(name_source, pred.max()))\n",
    "    '''\n",
    "    \n",
    "    # Convert the predicted class-scores to a one-dim array.\n",
    "    pred = np.squeeze(pred)\n",
    "\n",
    "    # The scores (probabilities) for the source and target classes.\n",
    "    score_source = pred[cls_source]\n",
    "    score_target = pred[cls_target]\n",
    "\n",
    "    return score_source > score_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple heuristic to implement total variance\n",
    "def tv_compress(image):\n",
    "    A = image\n",
    "    index1 = np.random.randint(0,A.shape[0],k)\n",
    "    index2 = np.random.randint(0,A.shape[1],k)\n",
    "    for x in range(100):\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(A.shape[1]):\n",
    "                cnt_ = 0\n",
    "                sum_ = 0\n",
    "                if(i > 0):\n",
    "                    cnt_ += 1\n",
    "                    sum_ += A[i-1, j]\n",
    "                if(j > 0):\n",
    "                    cnt_ += 1\n",
    "                    sum_ += A[i, j-1]\n",
    "                if(i < A.shape[0]-1):\n",
    "                    cnt_ += 1\n",
    "                    sum_ += A[i+1, j]\n",
    "                if(j < A.shape[1]-1):\n",
    "                    cnt_ += 1\n",
    "                    sum_ += A[i, j+1]\n",
    "                A[i, j] = sum_ / cnt_\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_compress(image, compress_bit):\n",
    "    compressed_image = image\n",
    "    for i in range(compressed_image.shape[0]):\n",
    "        for j in range(compressed_image.shape[1]):\n",
    "            for k in range(compressed_image.shape[2]):\n",
    "                compressed_image[i,j,k] -= compressed_image[i,j,k]% math.pow(2, compress_bit)\n",
    "    return compressed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(lst):\n",
    "    quotient, remainder = divmod(len(lst), 2)\n",
    "    if remainder:\n",
    "        return sorted(lst)[quotient]\n",
    "    return sum(sorted(lst)[quotient - 1:quotient + 1]) / 2.\n",
    "\n",
    "def checkindex(image, index_x, index_y):\n",
    "    if(index_x < 0 or index_x >= image.shape[0]):\n",
    "        return False;\n",
    "    if(index_y < 0 or index_y >= image.shape[1]):\n",
    "        return False;\n",
    "    return True;\n",
    "\n",
    "def find_median_in_sliding_windown(image, i, j, k, m, n):\n",
    "    list = []\n",
    "    for x in range(-m+1, m):\n",
    "        for y in range(-n+1, n):\n",
    "            if(checkindex(image, i+x, j+y)):\n",
    "                list.append(image[i+x, j+y, k])\n",
    "    return median(list)\n",
    "            \n",
    "# m = n = 1 is just using the pixel itself, i.e. no change\n",
    "def spatial_smoothing(image, m, n):\n",
    "    compressed_image = image\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            for k in range(image.shape[2]):\n",
    "                compressed_image[i, j, k] = find_median_in_sliding_windown(image, i, j, k, m, n)\n",
    "    return compressed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 norm is 0.0\n",
      "l2 norm is 0.022531122452808736\n",
      "l2 norm is 0.03014246426930797\n",
      "l2 norm is 0.03085954189255408\n",
      "l2 norm is 0.03619725852963769\n",
      "l2 norm is 0.03818029093055728\n",
      "l2 norm is 0.04185329800101976\n",
      "l2 norm is 0.043962517655200685\n",
      "l2 norm is 0.04679675824241529\n",
      "l2 norm is 0.04801016913512481\n",
      "l2 norm is 0.051686271221443494\n",
      "l2 norm is 0.0520740197715652\n",
      "[1.0, 1.0, 1.0, 0.0, 0.0]\n",
      "finished image \n",
      "l2 norm is 0.0\n",
      "l2 norm is 0.016823500015945646\n",
      "l2 norm is 0.025743949070831308\n",
      "l2 norm is 0.029909628168331346\n",
      "l2 norm is 0.03534242883471932\n",
      "l2 norm is 0.038353777501800836\n",
      "[2.0, 1.0, 1.0, 0.0, 0.0]\n",
      "finished image \n",
      "l2 norm is 0.0\n",
      "l2 norm is 0.023579679070496424\n",
      "l2 norm is 0.03274957571080144\n",
      "l2 norm is 0.03930352180854958\n"
     ]
    }
   ],
   "source": [
    "    total = len(images)\n",
    "    success = [0., 0., 0., 0., 0.]\n",
    "    threshold = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "    for image in images:\n",
    "        feed_dict = model._create_feed_dict(image_path=image)\n",
    "\n",
    "        #image = img[100]\n",
    "        #image_path= 'cifar/'\n",
    "        #feed_dict = model._create_feed_dict(image=image)\n",
    "\n",
    "\n",
    "\n",
    "        pred, image = session.run([y_pred, resized_image],\n",
    "                                      feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cls_source = np.argmax(pred)\n",
    "        cls_target = 300\n",
    "\n",
    "        # Score for the predicted class (aka. probability or confidence).\n",
    "        score_source_org = pred.max()\n",
    "\n",
    "        # Names for the source and target classes.\n",
    "        name_source = model.name_lookup.cls_to_name(cls_source,\n",
    "                                                    only_first_name=True)\n",
    "        name_target = model.name_lookup.cls_to_name(cls_target,\n",
    "                                                    only_first_name=True)\n",
    "\n",
    "        # Initialize the noise to zero.\n",
    "        noise = 0\n",
    "        iterations = 0\n",
    "        # Perform a number of optimization iterations to find\n",
    "        # the noise that causes mis-classification of the input image.\n",
    "        index = 0\n",
    "        for i in range(10000):\n",
    "            iterations = i\n",
    "            \n",
    "            # The noisy image is just the sum of the input image and noise.\n",
    "            noisy_image = image + noise\n",
    "\n",
    "            # Ensure the pixel-values of the noisy image are between\n",
    "            # 0 and 255 like a real image. If we allowed pixel-values\n",
    "            # outside this range then maybe the mis-classification would\n",
    "            # be due to this 'illegal' input breaking the Inception model.\n",
    "            noisy_image = np.clip(a=noisy_image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "            # Create a feed-dict. This feeds the noisy image to the\n",
    "            # tensor in the graph that holds the resized image, because\n",
    "            # this is the final stage for inputting raw image data.\n",
    "            # This also feeds the target class-number that we desire.\n",
    "            feed_dict = {model.tensor_name_resized_image: noisy_image,\n",
    "                         pl_cls_target: cls_target}\n",
    "\n",
    "            # Calculate the predicted class-scores as well as the gradient.\n",
    "            pred, grad = session.run([y_pred, gradient],\n",
    "                                     feed_dict=feed_dict)\n",
    "\n",
    "            # Convert the predicted class-scores to a one-dim array.\n",
    "            pred = np.squeeze(pred)\n",
    "\n",
    "            # The scores (probabilities) for the source and target classes.\n",
    "            score_source = pred[cls_source]\n",
    "            score_target = pred[cls_target]\n",
    "\n",
    "            # Squeeze the dimensionality for the gradient-array.\n",
    "            grad = np.array(grad).squeeze()\n",
    "\n",
    "            # The gradient now tells us how much we need to change the\n",
    "            # noisy input image in order to move the predicted class\n",
    "            # closer to the desired target-class.\n",
    "\n",
    "            # Calculate the max of the absolute gradient values.\n",
    "            # This is used to calculate the step-size.\n",
    "            grad_absmax = np.abs(grad).max()\n",
    "\n",
    "            # If the gradient is very small then use a lower limit,\n",
    "            # because we will use it as a divisor.\n",
    "            if grad_absmax < 1e-10:\n",
    "                grad_absmax = 1e-10\n",
    "\n",
    "            # Calculate the step-size for updating the image-noise.\n",
    "            # This ensures that at least one pixel colour is changed by 7.\n",
    "            # Recall that pixel colours can have 255 different values.\n",
    "            # This step-size was found to give fast convergence.\n",
    "            step_size = 1. / grad_absmax\n",
    "\n",
    "\n",
    "            '''\n",
    "            l2_disturb = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "\n",
    "            step_size = 0.1 / max(0.00001, math.sqrt(l2_disturb))\n",
    "            '''\n",
    "\n",
    "            test_precision(iterations, (image + noise)[0])\n",
    "\n",
    "            #l2_norm = np.linalg.norm(noise)/np.linalg.norm(image)\n",
    "            l2_norm = math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))\n",
    "            print ('l2 norm is {}'.format(math.sqrt(np.linalg.norm(noise)/np.linalg.norm(image))))\n",
    "\n",
    "            # If the score for the target-class is not high enough.\n",
    "            if index < len(threshold):\n",
    "            #if score_target < required_score and index < len(threshold):\n",
    "                # Update the image-noise by subtracting the gradient\n",
    "                # scaled by the step-size.\n",
    "                noise -= step_size * grad\n",
    "\n",
    "                # Ensure the noise is within the desired range.\n",
    "                # This avoids distorting the image too much.\n",
    "                noise = np.clip(a=noise,\n",
    "                                a_min=-noise_limit,\n",
    "                                a_max=noise_limit)\n",
    "                '''\n",
    "                if (iterations % 10 == 0):\n",
    "                    print(\"Print defense effect\")\n",
    "                    # Chose whatever defense method you want to use on the bottom.\n",
    "                    test_precision(iterations, spatial_smoothing((image + noise)[0], 3, 3))\n",
    "                '''\n",
    "                \n",
    "                if l2_norm >= threshold[index]:\n",
    "                    #print(\"inside while loop\")\n",
    "                    # Abort the optimization because the score is high enough.\n",
    "                    if(test_precision(iterations, bit_compress((image + noise)[0], 2))):\n",
    "                        #print(\"index is \", index)\n",
    "                        success[index] += 1.\n",
    "                        index += 1\n",
    "                    else:\n",
    "                        index += 10\n",
    "                    \n",
    "            else:  \n",
    "                print(success)\n",
    "                break;\n",
    "                \n",
    "        print(\"finished image \")\n",
    "    \n",
    "                \n",
    "    print(\"limit\", l2_limit, \"successful rate is \", success/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
